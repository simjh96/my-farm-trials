{"cells":[{"cell_type":"code","execution_count":1,"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","import os\n","import math\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["df = pd.read_csv(r'./data/top1.csv')"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["# fix random seed for reproducibility\n","np.random.seed(1)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["df = df.set_index('saleDate')"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["top1_arr = df.to_numpy()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["# normalize the dataset\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(top1_arr.reshape([-1,1]))"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["# split into train and test sets\n","train_size = int(len(dataset) * 0.67) \n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["def create_dataset(dataset, look_back=1):\n","    dataX, dataY = [], []\n","    \n","    for i in range(len(dataset) - look_back - 1):\n","        a = dataset[i:(i + look_back),:]\n","        dataX.append(a)\n","        dataY.append(dataset[i + look_back, 0])\n","    return np.array(dataX), np.array(dataY)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":21,"source":["# reshape into X=t and Y=t+1\n","look_back = 28\n","trainX, trainY = create_dataset(train, look_back)  \n","testX, testY = create_dataset(test, look_back)\n","\n","# reshape input to be  [samples, time steps, features]\n","trainX = np.reshape(trainX, (trainX.shape[0], look_back, 1))\n","testX = np.reshape(testX, (testX.shape[0],look_back, 1))"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["physical_devices = tf.config.list_physical_devices('GPU')\n","tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":23,"source":["# create and fit the LSTM network\n","\n","model = Sequential()\n","model.add(LSTM(4, input_shape=(look_back,1)))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","history= model.fit(trainX, trainY,validation_split=0.33, epochs=200, batch_size=32)\n","\n","# Plot training\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.show()"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","17/17 [==============================] - 15s 97ms/step - loss: 0.0493 - val_loss: 0.0236\n","Epoch 2/200\n","16/17 [===========================>..] - ETA: 0s - loss: 0.0358"]}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}